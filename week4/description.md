
# ğŸ§  Study Buddy â€” An Interactive Retrieval-Augmented AI Agent

**Study Buddy** is a Retrieval-Augmented Generation (RAG)-based AI assistant designed to help students engage with their study material intelligently. Instead of generating answers from scratch, it smartly searches your notes and delivers relevant, context-rich answers based on what *youâ€™ve already studied*.

This repository is part of a broader AI Agents initiative, focusing on **RAG pipelines, prompt engineering, fallback mechanisms, and confidence-aware LLM responses**.

---

## ğŸ¯ Project Objective

The primary goal is to build an interactive question-answering agent that:
- Retrieves relevant information from your **personal notes**
- Uses LLMs like OpenAI's GPT to construct high-quality, context-aware answers
- Handles a wide variety of questions: direct fact-based, reasoning-based, or general knowledge
- Incorporates ethical and fallback mechanisms to ensure safe and accurate responses
- Scores its own responses using both **heuristic** and **LLM-based** confidence estimation

---

## ğŸ’¡ Core Features

### ğŸ“„ PDF-to-Vector Indexing
- Notes (PDFs) placed in a directory are automatically:
  - Loaded using `PDFPlumber`
  - Split into chunks using `RecursiveCharacterTextSplitter`
  - Embedded via OpenAI Embeddings API
  - Stored in a vector store using **ChromaDB**

### ğŸ§  Multi-Strategy Query Routing
- Questions are classified into types such as:
  - `"rag"` â†’ Uses your notes
  - `"math"` â†’ Uses structured reasoning
  - `"wikipedia"` / `"tavily"` â†’ Uses external search
  - `"fallback"` â†’ Uses LLMâ€™s general knowledge

### ğŸ” Retrieval-Augmented Generation (RAG)
- When a user asks a question, the system:
  - Embeds the query
  - Searches the vector store for top-k similar chunks
  - Constructs a prompt that includes both question + retrieved notes
  - Sends this to OpenAI's Chat API for answer generation
    
### âœ… Confidence Evaluation
- After a response is generated, the system:
  - Computes a **heuristic confidence score** using:
    - Length, keyword overlap, semantic similarity, and presence of errors
  - Optionally asks the **LLM to rate itself** on accuracy and clarity
  - Combines both into a final confidence score

### ğŸ›¡ï¸ Ethical Guardrails
- Every user query and LLM response is checked for:
  - Harmful content
  - Ethically unsafe questions
- Users are warned or blocked when necessary

### ğŸ” Self-Correction
- If the confidence score is low:
  - The system attempts to **self-correct** the response using a refined prompt
  - If that fails, it falls back to general LLM knowledge

---

## ğŸ“ Repository Structure

```
code/
â”œâ”€â”€ main.py # Main CLI app for interactive Q&A
â”œâ”€â”€ rag.py # Document chunking, embedding, and retrieval
â”œâ”€â”€ call_llm.py # Unified interface to call OpenAI Chat API
â”œâ”€â”€ classify_query.py # Classifies question type (RAG, math, etc.) and re-structure query
â”œâ”€â”€ chat_history.py # Manages in-memory chat history and summarization
â”œâ”€â”€ prompt_design.py # Builds domain-aware prompts and instructions
â”œâ”€â”€ ethical_guardrail.py # Performs query and response compliance checks
â”œâ”€â”€ reasoning.py # Math reasoning, fallback strategy, self-correction
â”œâ”€â”€ tools.py # Interfaces to Tavily and Wikipedia search
```
---

## ğŸ› ï¸ How to Set Up

### 1. Clone the Repository
```
git clone https://github.com/DeblinaB1802/INTRO-TO-AI-AGENT.git
cd INTRO-TO-AI-AGENT/week4/code
```

### 2. Install Dependencies
```
pip install -r requirements.txt
```
If requirements.txt is not available, make sure to install:

langchain, chromadb, openai, pdfplumber, sentence-transformers, etc.

### 3. Prepare Your Study Notes

Place all your PDF files in the following folder:
```
notes/
```
The system will automatically parse, chunk, embed, and store them.

### 4. Set Your API Key
You can set your OpenAI and Tavily API key and url using an environment variable or hardcode it in the script (already present for testing):
```
export OPENAI_API_KEY="sk-..."
```
### â–¶ï¸ How to Run
Launch the Study Buddy CLI interface:
```
python main.py
```
You'll be prompted to enter your:
Educational level (used to adapt answer style)
Question

Then you'll receive a curated, AI-generated response based on:
Your personal notes
External knowledge (if needed)




